{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":6068,"sourceType":"modelInstanceVersion","modelInstanceId":4689,"modelId":2821}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Natural Language Processing with Disaster Tweets</h1>\n\n<a id = 'intro'></a>\n# Introduction\n<br>\nThis competition involves predicting which tweets are about actual disasters and which are not. The goal of this project is to get a submission CSV file which lists the tweet IDs with respective targets: any tweet that is about a disaster is marked with a 1; any non-disaster related tweet is marked 0. ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Import plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T02:06:04.662703Z","iopub.execute_input":"2025-06-22T02:06:04.662922Z","iopub.status.idle":"2025-06-22T02:06:04.687249Z","shell.execute_reply.started":"2025-06-22T02:06:04.662903Z","shell.execute_reply":"2025-06-22T02:06:04.686575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get current working directory\nos.getcwd()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T02:06:04.687877Z","iopub.execute_input":"2025-06-22T02:06:04.688136Z","iopub.status.idle":"2025-06-22T02:06:04.707192Z","shell.execute_reply.started":"2025-06-22T02:06:04.688108Z","shell.execute_reply":"2025-06-22T02:06:04.706339Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id='EDA'></a>\n# Exploratory Data Analysis\nBefore getting information on the training data, take a look at what the sample submission is expected to be. ","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsample.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T02:06:04.707870Z","iopub.execute_input":"2025-06-22T02:06:04.708145Z","iopub.status.idle":"2025-06-22T02:06:04.764998Z","shell.execute_reply.started":"2025-06-22T02:06:04.708125Z","shell.execute_reply":"2025-06-22T02:06:04.764371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, get basic information on the training data. Look at the train.csv file and get the first five rows of tweets.","metadata":{}},{"cell_type":"code","source":"# Get info on the training data\ntrain_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:44.390455Z","iopub.execute_input":"2025-06-22T03:18:44.390901Z","iopub.status.idle":"2025-06-22T03:18:44.420750Z","shell.execute_reply.started":"2025-06-22T03:18:44.390880Z","shell.execute_reply":"2025-06-22T03:18:44.420024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the columns' names on the train data\ntrain_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:44.574484Z","iopub.execute_input":"2025-06-22T03:18:44.574714Z","iopub.status.idle":"2025-06-22T03:18:44.579669Z","shell.execute_reply.started":"2025-06-22T03:18:44.574698Z","shell.execute_reply":"2025-06-22T03:18:44.578948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the train data structure's shape\ntrain_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:44.856486Z","iopub.execute_input":"2025-06-22T03:18:44.856730Z","iopub.status.idle":"2025-06-22T03:18:44.861476Z","shell.execute_reply.started":"2025-06-22T03:18:44.856713Z","shell.execute_reply":"2025-06-22T03:18:44.860767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:45.019799Z","iopub.execute_input":"2025-06-22T03:18:45.020457Z","iopub.status.idle":"2025-06-22T03:18:45.028179Z","shell.execute_reply.started":"2025-06-22T03:18:45.020436Z","shell.execute_reply":"2025-06-22T03:18:45.027484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get general info on train data\ntrain_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:45.247876Z","iopub.execute_input":"2025-06-22T03:18:45.248197Z","iopub.status.idle":"2025-06-22T03:18:45.259034Z","shell.execute_reply.started":"2025-06-22T03:18:45.248176Z","shell.execute_reply":"2025-06-22T03:18:45.258383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the count of unique values on train dataset\ntrain_data.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:50.380895Z","iopub.execute_input":"2025-06-22T03:18:50.381214Z","iopub.status.idle":"2025-06-22T03:18:50.393579Z","shell.execute_reply.started":"2025-06-22T03:18:50.381192Z","shell.execute_reply":"2025-06-22T03:18:50.392989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get descriptive statistics on train_data\ntrain_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:50.593668Z","iopub.execute_input":"2025-06-22T03:18:50.594157Z","iopub.status.idle":"2025-06-22T03:18:50.607150Z","shell.execute_reply.started":"2025-06-22T03:18:50.594136Z","shell.execute_reply":"2025-06-22T03:18:50.606518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, get information on the test data. ","metadata":{}},{"cell_type":"code","source":"# Get info on the test data\ntest_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:51.606245Z","iopub.execute_input":"2025-06-22T03:18:51.606745Z","iopub.status.idle":"2025-06-22T03:18:51.632452Z","shell.execute_reply.started":"2025-06-22T03:18:51.606721Z","shell.execute_reply":"2025-06-22T03:18:51.631727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:51.780454Z","iopub.execute_input":"2025-06-22T03:18:51.780916Z","iopub.status.idle":"2025-06-22T03:18:51.785450Z","shell.execute_reply.started":"2025-06-22T03:18:51.780897Z","shell.execute_reply":"2025-06-22T03:18:51.784745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:52.828986Z","iopub.execute_input":"2025-06-22T03:18:52.829419Z","iopub.status.idle":"2025-06-22T03:18:52.834525Z","shell.execute_reply.started":"2025-06-22T03:18:52.829393Z","shell.execute_reply":"2025-06-22T03:18:52.833732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:53.356672Z","iopub.execute_input":"2025-06-22T03:18:53.356945Z","iopub.status.idle":"2025-06-22T03:18:53.365957Z","shell.execute_reply.started":"2025-06-22T03:18:53.356925Z","shell.execute_reply":"2025-06-22T03:18:53.365364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check on the number of unique elements\ntest_data.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:53.544501Z","iopub.execute_input":"2025-06-22T03:18:53.544720Z","iopub.status.idle":"2025-06-22T03:18:53.553835Z","shell.execute_reply.started":"2025-06-22T03:18:53.544704Z","shell.execute_reply":"2025-06-22T03:18:53.553109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get descriptive statistics on the test data\ntest_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:54.344412Z","iopub.execute_input":"2025-06-22T03:18:54.345226Z","iopub.status.idle":"2025-06-22T03:18:54.354353Z","shell.execute_reply.started":"2025-06-22T03:18:54.345199Z","shell.execute_reply":"2025-06-22T03:18:54.353811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare the train and test data info and shapes\nprint(train_data.info(), test_data.info())\nprint(train_data.shape, test_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:55.401661Z","iopub.execute_input":"2025-06-22T03:18:55.401923Z","iopub.status.idle":"2025-06-22T03:18:55.417579Z","shell.execute_reply.started":"2025-06-22T03:18:55.401905Z","shell.execute_reply":"2025-06-22T03:18:55.416786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove the columns location, id from test_data; not necessary\ntest_data = test_data.loc[:, ['keyword', 'text']]\ntest_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:24:08.486735Z","iopub.execute_input":"2025-06-22T03:24:08.487244Z","iopub.status.idle":"2025-06-22T03:24:08.497005Z","shell.execute_reply.started":"2025-06-22T03:24:08.487221Z","shell.execute_reply":"2025-06-22T03:24:08.496389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get more info on train_data\nprint(train_data.columns)\ntrain_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:56.587907Z","iopub.execute_input":"2025-06-22T03:18:56.588618Z","iopub.status.idle":"2025-06-22T03:18:56.599154Z","shell.execute_reply.started":"2025-06-22T03:18:56.588595Z","shell.execute_reply":"2025-06-22T03:18:56.598187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_data[train_data['keyword'].isna()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:18:58.287025Z","iopub.execute_input":"2025-06-22T03:18:58.287325Z","iopub.status.idle":"2025-06-22T03:18:58.293193Z","shell.execute_reply.started":"2025-06-22T03:18:58.287307Z","shell.execute_reply":"2025-06-22T03:18:58.292479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_data[train_data['location'].isnull() | train_data['location'].isna()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:07.319020Z","iopub.execute_input":"2025-06-22T03:19:07.319324Z","iopub.status.idle":"2025-06-22T03:19:07.326997Z","shell.execute_reply.started":"2025-06-22T03:19:07.319304Z","shell.execute_reply":"2025-06-22T03:19:07.326204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Goal of the project is to match tweets with intended target (disastorous tweet marked 1; 0 otherwise)\n# Drop the id and location columns from the train_data frame\ntrain_data = train_data.loc[:, ['keyword', 'text', 'target']]\ntrain_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:14.674623Z","iopub.execute_input":"2025-06-22T03:19:14.674890Z","iopub.status.idle":"2025-06-22T03:19:14.684875Z","shell.execute_reply.started":"2025-06-22T03:19:14.674870Z","shell.execute_reply":"2025-06-22T03:19:14.684317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['keyword'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:16.669375Z","iopub.execute_input":"2025-06-22T03:19:16.669642Z","iopub.status.idle":"2025-06-22T03:19:16.676888Z","shell.execute_reply.started":"2025-06-22T03:19:16.669622Z","shell.execute_reply":"2025-06-22T03:19:16.676018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data['keyword'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:19.981037Z","iopub.execute_input":"2025-06-22T03:19:19.981849Z","iopub.status.idle":"2025-06-22T03:19:19.988527Z","shell.execute_reply.started":"2025-06-22T03:19:19.981818Z","shell.execute_reply":"2025-06-22T03:19:19.987879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['keyword'].value_counts().head(10).plot.bar()\nplt.title(\"Top 10 Keywords in Train Tweets\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:20.162106Z","iopub.execute_input":"2025-06-22T03:19:20.162338Z","iopub.status.idle":"2025-06-22T03:19:20.324020Z","shell.execute_reply.started":"2025-06-22T03:19:20.162321Z","shell.execute_reply":"2025-06-22T03:19:20.323333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['keyword'].value_counts().head(25).plot.bar()\nplt.title(\"Top 25 Keywords in Train Tweets\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:20.325042Z","iopub.execute_input":"2025-06-22T03:19:20.325296Z","iopub.status.idle":"2025-06-22T03:19:20.567467Z","shell.execute_reply.started":"2025-06-22T03:19:20.325280Z","shell.execute_reply":"2025-06-22T03:19:20.566728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A plot of the test data\ntest_data['keyword'].value_counts().head(10).plot.bar()\nplt.title(\"Top 10 Keywords in TestTweets\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:20.568631Z","iopub.execute_input":"2025-06-22T03:19:20.569296Z","iopub.status.idle":"2025-06-22T03:19:20.733675Z","shell.execute_reply.started":"2025-06-22T03:19:20.569276Z","shell.execute_reply":"2025-06-22T03:19:20.732995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:23.597677Z","iopub.execute_input":"2025-06-22T03:19:23.598262Z","iopub.status.idle":"2025-06-22T03:19:23.604109Z","shell.execute_reply.started":"2025-06-22T03:19:23.598239Z","shell.execute_reply":"2025-06-22T03:19:23.603432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(train_data, x='target')\nplt.xlabel(\"Type of Tweet\")\nplt.ylabel(\"Tweet Count\")\nplt.title(\"Train Data Tweet Type\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T03:19:23.807507Z","iopub.execute_input":"2025-06-22T03:19:23.807741Z","iopub.status.idle":"2025-06-22T03:19:23.919330Z","shell.execute_reply.started":"2025-06-22T03:19:23.807722Z","shell.execute_reply":"2025-06-22T03:19:23.918606Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id='Data Preparation'></a>\n# Data Preparation & Preprocessing\nSome data cleaning will be required because there is more than text that is in the tweets. \n<br>\nPrepare the training data before modeling. Install the necessary Keras and TensorFlow libraries to compare and build models to get the results.<br>\nAlso, this is the opportunity for presetting the Keras model and preprocessing the training data.","metadata":{}},{"cell_type":"code","source":"# Text cleaning is required since there are mentions, retweets, URLs, emojis, etc. that could be in the tweets. Remove these.\n# These are the libraries for text modifications\nimport re\nimport emoji\n!pip install contractions\nimport contractions\nimport html\n\n# Create function to clean up the tweets to be plain text\n# Get rid of additional characters or symbols\n# Credit belongs to https://www.kaggle.com/code/muhammadfaseeh/kerasnlp-starter-notebook-disaster-tweets\ndef get_clean_tweets(text):\n    \n    # Rid the tweets of any extra spaces leading or following the first or last word\n    text = text.strip()\n    \n    # Convert HTML entities\n    text = html.unescape(text)\n    \n    # Fix corrupted Unicode artifacts\n    text = text.replace(\"‰ÛÏ\", '\"').replace(\"‰Û\", '\"')  # Fix double quotes\n    text = text.replace(\"‰Û÷\", \"'\").replace(\"‰Ûª\", \"'\")  # Fix single quotes\n    text = text.replace(\"‰Û¢\", \"-\").replace(\"‰Û_\", \"-\")  # Fix hyphen issues\n    \n    # Remove any remaining corrupted symbols\n    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)  # Remove remaining non-ASCII characters\n    \n    # Remove URLs that start with 'https://...' or any links\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Remove mentions (@username)\n    text = re.sub(r'@\\w+', '', text)\n    \n    # Remove any emojis - had no idea that there was a library that could get this done\n    text = emoji.demojize(text, delimiters=(\" \", \" \"))  \n    \n    # Expand contractions\n    text = contractions.fix(text)\n\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:34:43.374711Z","iopub.execute_input":"2025-06-22T04:34:43.375257Z","iopub.status.idle":"2025-06-22T04:34:46.563937Z","shell.execute_reply.started":"2025-06-22T04:34:43.375234Z","shell.execute_reply":"2025-06-22T04:34:46.563015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply to both train and test tweets columns in datasets\ntrain_data['text'] = train_data['text'].apply(get_clean_tweets)\ntest_data['text'] = test_data['text'].apply(get_clean_tweets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:34:46.565434Z","iopub.execute_input":"2025-06-22T04:34:46.565752Z","iopub.status.idle":"2025-06-22T04:34:47.357923Z","shell.execute_reply.started":"2025-06-22T04:34:46.565719Z","shell.execute_reply":"2025-06-22T04:34:47.357285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:38:54.342240Z","iopub.execute_input":"2025-06-22T04:38:54.342938Z","iopub.status.idle":"2025-06-22T04:38:54.349728Z","shell.execute_reply.started":"2025-06-22T04:38:54.342919Z","shell.execute_reply":"2025-06-22T04:38:54.348908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:39:05.439284Z","iopub.execute_input":"2025-06-22T04:39:05.440019Z","iopub.status.idle":"2025-06-22T04:39:05.445913Z","shell.execute_reply.started":"2025-06-22T04:39:05.439994Z","shell.execute_reply":"2025-06-22T04:39:05.445033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import the appropriate libraries to split up the training data\nimport tensorflow as tf\nimport keras\nimport keras_nlp\nfrom keras import layers\nfrom keras.layers import TextVectorization\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:37.807705Z","iopub.execute_input":"2025-06-22T04:35:37.808206Z","iopub.status.idle":"2025-06-22T04:35:37.812374Z","shell.execute_reply.started":"2025-06-22T04:35:37.808184Z","shell.execute_reply":"2025-06-22T04:35:37.811622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get tensorflow, keras, keras_nlp versions\nprint(tf.__version__,\nkeras.__version__,\nkeras_nlp.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:39.091439Z","iopub.execute_input":"2025-06-22T04:35:39.091714Z","iopub.status.idle":"2025-06-22T04:35:39.096263Z","shell.execute_reply.started":"2025-06-22T04:35:39.091693Z","shell.execute_reply":"2025-06-22T04:35:39.095415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set batch size and get the text column for x; target column for y\nBATCH_SIZE = 16\nRANDOM_STATE = 101\n\nx = train_data['text']\ny = train_data['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:39.252398Z","iopub.execute_input":"2025-06-22T04:35:39.252614Z","iopub.status.idle":"2025-06-22T04:35:39.256865Z","shell.execute_reply.started":"2025-06-22T04:35:39.252600Z","shell.execute_reply":"2025-06-22T04:35:39.256009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(x), type(y), len(x), len(y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:40.088437Z","iopub.execute_input":"2025-06-22T04:35:40.088693Z","iopub.status.idle":"2025-06-22T04:35:40.093470Z","shell.execute_reply.started":"2025-06-22T04:35:40.088674Z","shell.execute_reply":"2025-06-22T04:35:40.092711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split up the data into train and validation sets\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=RANDOM_STATE)\n\nx_test = test_data['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:40.268464Z","iopub.execute_input":"2025-06-22T04:35:40.268660Z","iopub.status.idle":"2025-06-22T04:35:40.276876Z","shell.execute_reply.started":"2025-06-22T04:35:40.268646Z","shell.execute_reply":"2025-06-22T04:35:40.275964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(x), len(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:41.297522Z","iopub.execute_input":"2025-06-22T04:35:41.297789Z","iopub.status.idle":"2025-06-22T04:35:41.303377Z","shell.execute_reply.started":"2025-06-22T04:35:41.297770Z","shell.execute_reply":"2025-06-22T04:35:41.302669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(x_train), len(y_train), len(x_valid), len(y_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:41.544639Z","iopub.execute_input":"2025-06-22T04:35:41.544849Z","iopub.status.idle":"2025-06-22T04:35:41.548809Z","shell.execute_reply.started":"2025-06-22T04:35:41.544833Z","shell.execute_reply":"2025-06-22T04:35:41.548040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(x_train), type(x_valid), type(y_train), type(y_valid), type(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:41.756320Z","iopub.execute_input":"2025-06-22T04:35:41.756520Z","iopub.status.idle":"2025-06-22T04:35:41.760720Z","shell.execute_reply.started":"2025-06-22T04:35:41.756504Z","shell.execute_reply":"2025-06-22T04:35:41.760186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T04:35:41.989167Z","iopub.execute_input":"2025-06-22T04:35:41.989354Z","iopub.status.idle":"2025-06-22T04:35:41.993853Z","shell.execute_reply.started":"2025-06-22T04:35:41.989340Z","shell.execute_reply":"2025-06-22T04:35:41.993172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id='Model'></a>\n# Training the Model\n\nNow, time to train the model. <br>\nRe-compile the data, optimize the model, and then fit the data into the model. ","metadata":{}},{"cell_type":"code","source":"''' Credit for utilizing the model below deservedly goes to the following notebook: \nhttps://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-disaster-tweets#Preprocess-the-data\n\nI would not have learned about the different kinds of models that Keras has to offer with text classification without seeing what was possible with the models implemented and the information it had \nin comparison and research to other preser Keras English language recognition models. This made work on this project much easier. \n'''\n\n# Load DistilBERT model, uncased and based.\npreset= \"distil_bert_base_en_uncased\"\n\n# Use a shorter sequence length - 140\npreprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n                                                                   sequence_length=140,\n                                                                   name=\"preprocessor_4_tweets\"\n                                                                  )\n\n# Pretrain the classifier for model\nclassifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,preprocessor = preprocessor, \n                                                               num_classes=2)\n\nclassifier.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T05:10:13.781307Z","iopub.execute_input":"2025-06-22T05:10:13.781607Z","iopub.status.idle":"2025-06-22T05:10:19.593790Z","shell.execute_reply.started":"2025-06-22T05:10:13.781586Z","shell.execute_reply":"2025-06-22T05:10:19.593245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Re-compile data with different learning rate\n\nclassifier.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  optimizer=keras.optimizers.Adam(1e-5),\n                  metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T05:11:38.865684Z","iopub.execute_input":"2025-06-22T05:11:38.865946Z","iopub.status.idle":"2025-06-22T05:11:38.875191Z","shell.execute_reply.started":"2025-06-22T05:11:38.865927Z","shell.execute_reply":"2025-06-22T05:11:38.874441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Fit the data into the model\n# Set number of epochs to 10\nmodel = classifier.fit(x=x_train, \n          y=y_train,\n          batch_size=BATCH_SIZE,\n       validation_data=(x_valid,y_valid),\n           epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T05:41:32.020609Z","iopub.execute_input":"2025-06-22T05:41:32.020877Z","iopub.status.idle":"2025-06-22T05:58:29.154540Z","shell.execute_reply.started":"2025-06-22T05:41:32.020861Z","shell.execute_reply":"2025-06-22T05:58:29.153797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get logs - a full dictionary\nprint(model.history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:01:30.351968Z","iopub.execute_input":"2025-06-22T06:01:30.352656Z","iopub.status.idle":"2025-06-22T06:01:30.356429Z","shell.execute_reply.started":"2025-06-22T06:01:30.352632Z","shell.execute_reply":"2025-06-22T06:01:30.355777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get keys to save the training and validation logs percentages for each epoch\nmodel.history.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:02:44.253225Z","iopub.execute_input":"2025-06-22T06:02:44.253894Z","iopub.status.idle":"2025-06-22T06:02:44.258829Z","shell.execute_reply.started":"2025-06-22T06:02:44.253873Z","shell.execute_reply":"2025-06-22T06:02:44.258078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# number of values in each list should align to how many epochs were needed to train\nloss = model.history['loss']\nval_loss = model.history['val_loss']\naccuracy = model.history['accuracy']\nval_accuracy = model.history['val_accuracy']\nprint(len(loss), type(loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:04:59.102539Z","iopub.execute_input":"2025-06-22T06:04:59.103049Z","iopub.status.idle":"2025-06-22T06:04:59.107388Z","shell.execute_reply.started":"2025-06-22T06:04:59.103029Z","shell.execute_reply":"2025-06-22T06:04:59.106766Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id='Plots'></a>\n# Plotting Loss\nGather all the information from model's history and plot the curves to see how the training data did against the validation data. ","metadata":{}},{"cell_type":"code","source":"# Initialize x-axis for plots - first plot the loss\nepochs = list(range(1, len(loss) + 1))\n\nplt.figure()\nplt.plot(epochs, loss, label='Training Loss')\nplt.plot(epochs, val_loss, label='Validation Loss')\nplt.title(\"Loss during Training\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:21:57.301495Z","iopub.execute_input":"2025-06-22T06:21:57.301957Z","iopub.status.idle":"2025-06-22T06:21:57.456047Z","shell.execute_reply.started":"2025-06-22T06:21:57.301936Z","shell.execute_reply":"2025-06-22T06:21:57.455439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now plot the accuracy\nplt.figure()\nplt.plot(epochs, accuracy, label='Training Accuracy')\nplt.plot(epochs, val_accuracy, label='Validation Accuracy')\nplt.title(\"Accuracy during Training\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:23:11.792988Z","iopub.execute_input":"2025-06-22T06:23:11.793264Z","iopub.status.idle":"2025-06-22T06:23:11.961292Z","shell.execute_reply.started":"2025-06-22T06:23:11.793248Z","shell.execute_reply":"2025-06-22T06:23:11.960547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate Confusion Matrix\ndef getConfusionMatrix(y_true, y_pred, data):\n    matr = ConfusionMatrixDisplay.from_predictions(y_true, np.argmax(y_pred, axis=1),\n                                                  display_labels=['Not Disaster Tweet', 'Disaster Tweet'])\n    true_neg, false_pos, false_neg, true_pos = confusion_matrix(y_true, np.argmax(y_pred, axis=1)).ravel()\n    precision = true_pos / (true_pos + false_pos)\n    recall = true_pos / (true_pos + false_neg)\n    f1 = 2 * ( (precision * recall) / (precision + recall))\n    matr.ax_.set_title(\"Confusion Matrix on \" + data + \" Dataset -- F1 Score: \" + str(f1.round(3)))\n    print(precision, recall)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:00:02.012499Z","iopub.execute_input":"2025-06-22T07:00:02.013033Z","iopub.status.idle":"2025-06-22T07:00:02.018541Z","shell.execute_reply.started":"2025-06-22T07:00:02.013013Z","shell.execute_reply":"2025-06-22T07:00:02.017668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict model on x_train \ny_pred_train = classifier.predict(x_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:38:07.129314Z","iopub.execute_input":"2025-06-22T06:38:07.129602Z","iopub.status.idle":"2025-06-22T06:38:44.262603Z","shell.execute_reply.started":"2025-06-22T06:38:07.129583Z","shell.execute_reply":"2025-06-22T06:38:44.261958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the Confusion Matrix for training data\ngetConfusionMatrix(y_train, y_pred_train, \"Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:00:04.936651Z","iopub.execute_input":"2025-06-22T07:00:04.936932Z","iopub.status.idle":"2025-06-22T07:00:05.126101Z","shell.execute_reply.started":"2025-06-22T07:00:04.936912Z","shell.execute_reply":"2025-06-22T07:00:05.125364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict model on x_val \ny_pred_valid = classifier.predict(x_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:41:39.797629Z","iopub.execute_input":"2025-06-22T06:41:39.797936Z","iopub.status.idle":"2025-06-22T06:41:50.872490Z","shell.execute_reply.started":"2025-06-22T06:41:39.797898Z","shell.execute_reply":"2025-06-22T06:41:50.871725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the Confusion Matrix for the validation data\ngetConfusionMatrix(y_valid, y_pred_valid, \"Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:00:08.788105Z","iopub.execute_input":"2025-06-22T07:00:08.788856Z","iopub.status.idle":"2025-06-22T07:00:08.980818Z","shell.execute_reply.started":"2025-06-22T07:00:08.788832Z","shell.execute_reply":"2025-06-22T07:00:08.980020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the sample submission file\nsample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T06:57:56.158370Z","iopub.execute_input":"2025-06-22T06:57:56.158910Z","iopub.status.idle":"2025-06-22T06:57:56.167168Z","shell.execute_reply.started":"2025-06-22T06:57:56.158887Z","shell.execute_reply":"2025-06-22T06:57:56.166404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id='Conclusion'></a>\n# Conclusion and Submission\n\nIt can be seen from the confusion matrices that we received some levels of accuracy running the preprocessing and modeling through DistilBERT. <br>\nThe F1 score received for the training data was 0.985, and the validation data 0.757, provided that the validation set was smaller than the training set. <br>\nThere was not much training loss between any of the epochs, as it stayed well below 10% most of the time. <br>\nIt can also be seen that there were a couple of sharp periods of increases when it came to the validation loss. <br>\nAs for the modeling accuracy, the training rate stayed well above 95%, while the validation data model epochs runs ranged anywhere from 79% to 82%. <br>\nIn the validation prediction confusion matrix, there was an equal number of false negative and false positive predictions with 150 and 158, respectively. <br>\n\n<h2>Improvements</h2>\nAny means of improvement can be made to how the text preprocessing was implemented. There certainly are better and more efficient ways of getting rid of extra characters prior to splitting and preprocessing for modeling. A more extensive data analysis and pre-preprocessing, though it may appear unnecessary, would have helped with garnering more accurate results. There were several processing errors trying to fit the data to the model because of how tweets that are text are not always text. Thus, any credit to fellow Kaggle users deserve much thanks, because this notebook would not have run properly without realizing how important it is to periodically look through some of the tweets line by line. \n<br>\nAdditionally, a different kind of model framework from Keras or TensorFlow would have netted different results. The use of a different count of epochs would have also given the model being trained more opportunities to improve its accuracy. \n","metadata":{}},{"cell_type":"code","source":"# Alter the submission file column target with the predictions to submit\n# Use x_test data for the prediction\nsample['target'] = np.argmax(classifier.predict(x_test), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:24:30.370943Z","iopub.execute_input":"2025-06-22T07:24:30.371738Z","iopub.status.idle":"2025-06-22T07:24:52.264201Z","shell.execute_reply.started":"2025-06-22T07:24:30.371711Z","shell.execute_reply":"2025-06-22T07:24:52.263553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:25:23.073614Z","iopub.execute_input":"2025-06-22T07:25:23.074122Z","iopub.status.idle":"2025-06-22T07:25:23.080832Z","shell.execute_reply.started":"2025-06-22T07:25:23.074101Z","shell.execute_reply":"2025-06-22T07:25:23.080125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:25:27.019350Z","iopub.execute_input":"2025-06-22T07:25:27.019595Z","iopub.status.idle":"2025-06-22T07:25:27.031755Z","shell.execute_reply.started":"2025-06-22T07:25:27.019580Z","shell.execute_reply":"2025-06-22T07:25:27.031214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create new submission CSV file - submit to 'submission.csv'\nsample.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:26:11.953914Z","iopub.execute_input":"2025-06-22T07:26:11.954499Z","iopub.status.idle":"2025-06-22T07:26:11.970477Z","shell.execute_reply.started":"2025-06-22T07:26:11.954478Z","shell.execute_reply":"2025-06-22T07:26:11.969945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}